{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgH-QAQzHySY"
   },
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0343CTgTHySZ",
    "outputId": "034cd2e2-cde3-406c-ac11-7f72d6f6a5e3"
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "path = 'mypath'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6d35n0uHySe",
    "outputId": "c161693e-b43f-4a3d-d095-98126ecb09a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVdjxGx3Lywv"
   },
   "outputs": [],
   "source": [
    "xr_train = xr.open_dataset(path+'xr_train_timestamped.netcdf')\n",
    "xr_test = xr.open_dataset(path+'xr_test_timestamped.netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsoLT-Ba9eun"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def get_seq_length(past_dict = {'year': 0, 'month': 0, 'week': 0, 'day': 0, 'hour': 1},\n",
    "                   future_dict = {'year': 0, 'month': 0, 'week': 0, 'day': 0, 'hour': 1},\n",
    "                   max_len = 133992):\n",
    "  look_up = (past_dict['hour'] * 4 + past_dict['day'] * 24 * 4\n",
    "            + past_dict['month'] *30 * 24 * 4 + past_dict['year'] * 12 * 30 * 24 * 4)\n",
    "  look_ahead = (future_dict['hour'] * 4 + future_dict['day'] * 24 * 4\n",
    "                + future_dict['month'] *30 * 24 * 4 + future_dict['year'] * 12 * 30 * 24 * 4)\n",
    "\n",
    "  if look_up+look_ahead > max_len:\n",
    "    print('Not enough data to accomodate requested sequence lengths, returning 1 and 1')\n",
    "    look_up, look_ahead = 1, 1\n",
    "\n",
    "  return look_up, look_ahead\n",
    "\n",
    "\n",
    "class PVDataset(Dataset):\n",
    "  def __init__(self, X, look_up=1, look_ahead=1):\n",
    "\n",
    "    '''\n",
    "    X = xarray dataset\n",
    "    look_up = int, length of sequence of past observations to use for prediction\n",
    "    look_ahead = int, length of sequence to predict\n",
    "    '''\n",
    "\n",
    "    self.X = X\n",
    "    self.stations = list(X.keys())\n",
    "    self.look_up = look_up\n",
    "    self.look_ahead = look_ahead\n",
    "    self.shape_0 = X.dims['datetime']\n",
    "    self.shape_1 = len(self.stations)\n",
    "    self.data_len = self.shape_0 // (self.look_up + self.look_ahead)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.data_len * self.shape_1\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "\n",
    "    ss_num = i // self.data_len\n",
    "    ss_id = self.stations[ss_num]\n",
    "    i = (i % self.shape_1) * (self.look_up + self.look_ahead)\n",
    "\n",
    "    t = i + self.look_up\n",
    "\n",
    "    while sum(self.X[ss_id].data[t-self.look_up : t]) < 0.5:\n",
    "      i = np.random.choice(list(range(self.__len__())), 1)[0]\n",
    "      ss_num = i // self.data_len\n",
    "      ss_id = self.stations[ss_num]\n",
    "      i = (i % self.shape_1) * (self.look_up + self.look_ahead)\n",
    "\n",
    "      t = i + self.look_up\n",
    "\n",
    "    x_item = np.zeros((self.look_up, 5))\n",
    "    y_item = np.zeros((self.look_ahead, 1))\n",
    "\n",
    "    x_item[:, 0], y_item = self.X[ss_id].data[t-self.look_up : t], self.X[ss_id].data[t : t+self.look_ahead]\n",
    "    x_item[:, 1] = self.X.date_sin.data[t-self.look_up : t]\n",
    "    x_item[:, 2] = self.X.date_cos.data[t-self.look_up : t]\n",
    "    x_item[:, 3] = self.X.time_sin.data[t-self.look_up : t]\n",
    "    x_item[:, 4] = self.X.time_sin.data[t-self.look_up : t]\n",
    "\n",
    "    return torch.Tensor(x_item).float(), torch.Tensor(y_item).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKfRNXGoHyS0"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def loaders(xr_test, xr_train, batch_size, dict_look_up, dict_look_ahead, sample=False):\n",
    "\n",
    "  max_len = len(xr_train['datetime'].data)\n",
    "\n",
    "  look_up, look_ahead = get_seq_length(past_dict=dict_look_up, future_dict=dict_look_ahead, max_len=max_len)\n",
    "\n",
    "  train_dataset = PVDataset(xr_train, look_up, look_ahead)\n",
    "  test_dataset = PVDataset(xr_test, look_up, look_ahead)\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "  print(\"Expected number of steps is %d\" %((train_dataset.__len__()  + batch_size - 1) // batch_size))\n",
    "\n",
    "  return train_loader, test_loader, look_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPu01RUQHyS4"
   },
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "\n",
    "  def __init__(self, hidden_size,\n",
    "               num_layers,\n",
    "               out_features,\n",
    "               input_size,\n",
    "               dropout=0):\n",
    "\n",
    "    super().__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = num_layers\n",
    "    self.lstm = nn.LSTM(input_size=input_size,\n",
    "                        hidden_size=hidden_size,\n",
    "                        num_layers=num_layers,\n",
    "                        batch_first=True,\n",
    "                        dropout=dropout\n",
    "                        )\n",
    "\n",
    "    self.fc = nn.Linear(in_features=hidden_size, out_features=out_features)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "\n",
    "    h_t = torch.zeros(self.num_layers,\n",
    "                      batch_size,\n",
    "                      self.hidden_size).to(device)\n",
    "    c_t = torch.zeros(self.num_layers,\n",
    "                      batch_size,\n",
    "                      self.hidden_size).to(device)\n",
    "\n",
    "\n",
    "    _, (h_out, c_n) = self.lstm(x, (h_t, c_t))\n",
    "\n",
    "    h_out = h_out[0].view(-1, self.hidden_size)\n",
    "\n",
    "    out = self.fc(h_out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2cLdZMXHyS7"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, loss_function, print_every=500):\n",
    "  loss_array = []\n",
    "  model.train(True)\n",
    "  running_loss = 0.\n",
    "\n",
    "  for batch_index, batch in enumerate(train_loader):\n",
    "    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "    output = model(x_batch)\n",
    "\n",
    "    loss = loss_function(output, y_batch.squeeze())\n",
    "    running_loss += loss.item()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_index % print_every == 0:\n",
    "      loss_array.append(running_loss/print_every)\n",
    "      print(\"Batch %d, loss: %f\" %(batch_index+1, running_loss/print_every))\n",
    "      running_loss=0.\n",
    "\n",
    "  loss_array.append(running_loss/((batch_index+1)%1000))\n",
    "\n",
    "  print()\n",
    "  return loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKOT3nmyHyS8"
   },
   "outputs": [],
   "source": [
    "def validate_epoch(model, test_loader, loss_function):\n",
    "  model.train(False)\n",
    "  running_loss = 0.\n",
    "\n",
    "  for batch_index, batch in enumerate(test_loader):\n",
    "    x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      output = model(x_batch)\n",
    "      loss = loss_function(output, y_batch.squeeze())\n",
    "      running_loss += loss.item()\n",
    "\n",
    "  avg_loss = running_loss / len(test_loader)\n",
    "\n",
    "  print('Val loss: {0:.5f}'.format(avg_loss))\n",
    "  print('_______________________________')\n",
    "  print()\n",
    "\n",
    "  return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApcdGrJu4DJS"
   },
   "source": [
    "### best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWAEWhj-4TMx"
   },
   "outputs": [],
   "source": [
    "best_params_df = pd.read_csv(path+'baseline_best_params.csv')\n",
    "best_params = best_params_df.loc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsitr7xd4JiK",
    "outputId": "c50d54f6-4b0c-4cb7-d836-7f9aa4301f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of steps is 3052\n",
      "{'input_size': 5, 'hidden_size': 64, 'num_layers': 3, 'out_features': 24, 'dropout': 0.113318450480939}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM_model(\n",
       "  (lstm): LSTM(5, 64, num_layers=3, batch_first=True, dropout=0.113318450480939)\n",
       "  (fc): Linear(in_features=64, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_params = {\n",
    "    'xr_test':  xr_test,\n",
    "    'xr_train': xr_train,\n",
    "    'batch_size': 64,\n",
    "    'dict_look_up': {'year': 0, 'month': 0, 'week': 0, 'day': 0, 'hour': int(best_params['look_up'])},\n",
    "    'dict_look_ahead': {'year': 0, 'month': 0, 'week': 0, 'day': 0, 'hour': 6},\n",
    "}\n",
    "\n",
    "train_loader, test_loader, look_ahead = loaders(**data_params)\n",
    "\n",
    "model_params = {\n",
    "    'input_size': 5,\n",
    "    'hidden_size':  int(best_params['hidden_size']),\n",
    "    'num_layers':   int(best_params['num_layers']),\n",
    "    'out_features': look_ahead,\n",
    "    'dropout':      best_params['dropout']\n",
    "}\n",
    "\n",
    "print(model_params)\n",
    "\n",
    "model = LSTM_model(**model_params)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8bE55LJ9Ohh",
    "outputId": "6f6eafc5-439a-4615-f878-a26f62bb0905"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 6\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "best_loss = 1\n",
    "best_epoch = 0\n",
    "for epoch in range(num_epochs):\n",
    "  print('Epoch:', epoch+1)\n",
    "  train_loss.append(train_epoch(model=model, train_loader=train_loader,\n",
    "                                optimizer=optimizer,\n",
    "                                loss_function=loss_function,\n",
    "                                print_every=300))\n",
    "  test_loss.append(validate_epoch(model=model, test_loader=test_loader, loss_function=loss_function))\n",
    "  if test_loss[-1] < best_loss:\n",
    "    best_loss = test_loss[-1]\n",
    "    best_epoch = epoch\n",
    "  if epoch - best_epoch >= 2:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InRmMsojJ7yr"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), path+'baseline_model')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "wtFyfTaZcVUB",
    "UfWq69jVcVUG",
    "wVbwTql1h0P1",
    "pdDXxxJocVUP",
    "CemS6sOJjHes",
    "p34I-x72cVUT",
    "73rUY1QEdA41",
    "0KEVzJzeZym1"
   ],
   "gpuType": "V100",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
